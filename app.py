import streamlit as st
import joblib
import google.generativeai as genai

# 1. Configuraci√≥n de API
genai.configure(api_key=st.secrets["API_KEY"])

# 2. Carga del modelo local
modelo_local = joblib.load('modelo_libros.pkl')

# 3. Interfaz
st.set_page_config(page_title="BiblioIA")
st.title("üìö Mi Recomendador de Libros")
st.write("Tu IA local detecta el g√©nero y Gemini te recomienda los mejores t√≠tulos.")

user_input = st.text_input("¬øQu√© libro te apetece leer hoy?")

if st.button("Recomendar"):
    if user_input:
        try:
            # A. Predicci√≥n con tu modelo local (esto ya te funciona bien)
            genero = modelo_local.predict([user_input])[0]
            st.info(f"üîç G√©nero detectado por el modelo local: **{genero}**")

            # B. Llamada a Gemini con la versi√≥n de modelo m√°s estable
            # Usamos 'gemini-1.5-flash' sin prefijos para evitar el error 404 de v1beta
            model = genai.GenerativeModel('gemini-1.5-flash')
            
            prompt = f"Basado en que el usuario busca '{user_input}' y el g√©nero es '{genero}', recomienda 3 libros reales y explica brevemente por qu√©."
            
            response = model.generate_content(prompt)
            
            st.success("‚ú® **Sugerencias de Gemini:**")
            st.write(response.text)
            
        except Exception as e:
            st.error(f"Hubo un problema con la recomendaci√≥n: {e}")
    else:
        st.warning("Por favor, escribe algo primero.")
